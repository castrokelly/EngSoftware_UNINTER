{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Kelly Christine Alvarenga de Castro - Engenharia de Software UNINTER\n",
    "## Sistema Preditivo de Falhas em Equipamentos da Indústria de Energia\n",
    "### Notebook de Exploração de Dados e Treinamento de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Este notebook tem como objetivo explorar os dados processados das turbinas eólicas, realizar a engenharia de features adicionais (se necessário), treinar diferentes modelos de aprendizado de máquina para prever falhas e avaliar seu desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import awswrangler as wr # Para ler dados do S3\n",
    "import os\n",
    "import joblib # Para salvar modelos treinados\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Configurações do Matplotlib e Seaborn para melhores visualizações\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregamento dos Dados Processados (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o bucket S3 onde os dados processados (features em Parquet) estão armazenados\n",
    "PROCESSED_DATA_BUCKET = os.environ.get(\"PROCESSED_DATA_BUCKET_NAME\", \"tcc-kelly-processed-turbine-data-bucket\")\n",
    "FEATURES_S3_PATH = f\"s3://{PROCESSED_DATA_BUCKET}/features/\"\n",
    "\n",
    "# Listar arquivos Parquet no diretório de features\n",
    "try:\n",
    "    feature_files = wr.s3.list_objects(path=FEATURES_S3_PATH)\n",
    "    parquet_files = [f for f in feature_files if f.endswith('.parquet')]\n",
    "    print(f\"Arquivos Parquet encontrados: {len(parquet_files)}\")\n",
    "    # print(parquet_files[:5]) # Mostrar os primeiros 5 arquivos\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao listar arquivos no S3: {e}\")\n",
    "    parquet_files = []\n",
    "\n",
    "# Carregar todos os arquivos Parquet em um único DataFrame do Pandas\n",
    "if parquet_files:\n",
    "    try:\n",
    "        df_features = wr.s3.read_parquet(path=parquet_files) # awswrangler pode ler múltiplos arquivos\n",
    "        print(\"Dados de features carregados com sucesso!\")\n",
    "        print(f\"Shape do DataFrame: {df_features.shape}\")\n",
    "        display(df_features.head())\n",
    "        display(df_features.info())\n",
    "        display(df_features.describe().T)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar dados Parquet do S3: {e}\")\n",
    "        df_features = pd.DataFrame() # DataFrame vazio em caso de erro\n",
    "else:\n",
    "    print(\"Nenhum arquivo de features encontrado para carregar.\")\n",
    "    df_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pré-processamento e Análise Exploratória dos Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_features.empty:\n",
    "    # Verificar valores ausentes\n",
    "    print(\"\nValores Ausentes por Coluna:\")\n",
    "    print(df_features.isnull().sum())\n",
    "    \n",
    "    # Tratar valores ausentes (ex: preencher com média, mediana ou remover linhas/colunas)\n",
    "    # Para features como std, se a janela tiver apenas 1 ponto, std será NaN. Pode ser preenchido com 0.\n",
    "    for col in df_features.columns:\n",
    "        if '_std' in col and df_features[col].isnull().any():\n",
    "            print(f'Preenchendo NaNs na coluna {col} com 0.')\n",
    "            df_features[col].fillna(0, inplace=True)\n",
    "            \n",
    "    # Remover linhas com NaNs restantes, se houver e for apropriado\n",
    "    # df_features.dropna(inplace=True) \n",
    "    \n",
    "    # Converter 'window_end_timestamp' para datetime se não estiver\n",
    "    if 'window_end_timestamp' in df_features.columns:\n",
    "        df_features['window_end_timestamp'] = pd.to_datetime(df_features['window_end_timestamp'])\n",
    "        df_features.sort_values(by='window_end_timestamp', inplace=True)\n",
    "        df_features.set_index('window_end_timestamp', inplace=True, drop=False) # Manter a coluna e usar como índice\n",
    "        \n",
    "    # Distribuição da variável alvo 'label'\n",
    "    if 'label' in df_features.columns:\n",
    "        print(\"\nDistribuição da Variável Alvo (label):\")\n",
    "        print(df_features['label'].value_counts(normalize=True) * 100)\n",
    "        sns.countplot(x='label', data=df_features)\n",
    "        plt.title('Distribuição das Classes (0: Normal, 1: Falha Caixa Eng., 2: Falha Vibração)')\n",
    "        plt.show()\n",
    "        \n",
    "        # Para classificação binária (falha vs não falha), podemos converter label > 0 para 1\n",
    "        # df_features['label_binary'] = df_features['label'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        # sns.countplot(x='label_binary', data=df_features)\n",
    "        # plt.title('Distribuição Binária das Classes (0: Normal, 1: Falha)')\n",
    "        # plt.show()\n",
    "    else:\n",
    "        print(\"Coluna 'label' não encontrada para análise de distribuição.\")\n",
    "\n",
    "    # Visualizar algumas features ao longo do tempo (exemplo)\n",
    "    sample_turbine_id = df_features['turbine_id'].unique()[0] if 'turbine_id' in df_features.columns and len(df_features['turbine_id'].unique()) > 0 else None\n",
    "    if sample_turbine_id:\n",
    "        df_sample_turbine = df_features[df_features['turbine_id'] == sample_turbine_id]\n",
    "        if not df_sample_turbine.empty:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.subplot(2,1,1)\n",
    "            plt.plot(df_sample_turbine.index, df_sample_turbine['gearbox_temperature_c_mean'], label='Temp. Média Caixa Eng.')\n",
    "            if 'label' in df_sample_turbine.columns:\n",
    "                plt.scatter(df_sample_turbine[df_sample_turbine['label'] == 1].index, df_sample_turbine[df_sample_turbine['label'] == 1]['gearbox_temperature_c_mean'], color='red', label='Falha Caixa Eng. (Label 1)')\n",
    "            plt.title(f'Temperatura Média da Caixa de Engrenagens - Turbina {sample_turbine_id}')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(2,1,2)\n",
    "            plt.plot(df_sample_turbine.index, df_sample_turbine['vibration_x_g_mean'], label='Vibração X Média')\n",
    "            if 'label' in df_sample_turbine.columns:\n",
    "                plt.scatter(df_sample_turbine[df_sample_turbine['label'] == 2].index, df_sample_turbine[df_sample_turbine['label'] == 2]['vibration_x_g_mean'], color='orange', label='Falha Vibração (Label 2)')\n",
    "            plt.title(f'Vibração Média Eixo X - Turbina {sample_turbine_id}')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Correlação entre features (heatmap)\n",
    "    numeric_cols = df_features.select_dtypes(include=np.number).columns.tolist()\n",
    "    if 'label' in numeric_cols: # Remover label temporariamente para não enviesar correlação de features puras\n",
    "        numeric_cols_no_label = [col for col in numeric_cols if col != 'label']\n",
    "    else:\n",
    "        numeric_cols_no_label = numeric_cols\n",
    "        \n",
    "    if len(numeric_cols_no_label) > 1:\n",
    "        plt.figure(figsize=(18, 15))\n",
    "        correlation_matrix = df_features[numeric_cols_no_label].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "        plt.title('Heatmap de Correlação das Features Numéricas')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"DataFrame de features está vazio. EDA não pode ser realizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preparação dos Dados para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_features.empty and 'label' in df_features.columns:\n",
    "    # Selecionar features (X) e variável alvo (y)\n",
    "    # Remover colunas não preditivas ou que vazam informação (ex: timestamp, turbine_id se não for usada como feature)\n",
    "    features_to_drop = ['window_end_timestamp', 'turbine_id', 'label'] # Adicionar outras se necessário\n",
    "    X = df_features.drop(columns=[col for col in features_to_drop if col in df_features.columns])\n",
    "    y = df_features['label'] # Ou 'label_binary' se criada\n",
    "    \n",
    "    # Garantir que todas as colunas em X são numéricas\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "    X.fillna(X.mean(), inplace=True) # Preencher NaNs restantes com a média da coluna (cuidado com essa abordagem)\n",
    "\n",
    "    print(f\"Shape de X (features): {X.shape}\")\n",
    "    print(f\"Shape de y (alvo): {y.shape}\")\n",
    "    display(X.head())\n",
    "\n",
    "    # Divisão dos dados em treino e teste\n",
    "    # Para séries temporais, é importante evitar data leakage. \n",
    "    # Uma abordagem é usar TimeSeriesSplit ou dividir cronologicamente.\n",
    "    # Por simplicidade aqui, vamos usar train_test_split, mas com shuffle=False se o índice for temporal.\n",
    "    # Se o índice não for mais o timestamp, o shuffle pode ser True, mas cuidado com a ordem original dos dados de janela.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True, stratify=y if y.nunique() > 1 else None)\n",
    "    # Para TimeSeriesSplit (mais apropriado para dados de janela ordenados no tempo):
",
    "    # tscv = TimeSeriesSplit(n_splits=5)
",
    "    # for train_index, test_index in tscv.split(X):
",
    "    #     X_train, X_test = X.iloc[train_index], X.iloc[test_index]
",
    "    #     y_train, y_test = y.iloc[train_index], y.iloc[test_index]
",
    "    # (Este é um loop, para uso em CV. Para split único, ajustar)
",
    "    \n",
    "    print(f\"Shape de X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Shape de X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    # Normalização/Padronização das features (importante para SVM, Reg. Logística, Redes Neurais)\n",
    "    scaler = StandardScaler() # Ou MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Salvar o scaler para uso na API de inferência\n",
    "    scaler_filename = '/home/ubuntu/tcc_kelly_castro/notebooks/feature_scaler.joblib'\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f'Scaler salvo em {scaler_filename}')\n",
    "else:\n",
    "    print(\"DataFrame de features vazio ou sem coluna 'label'. Modelagem não pode prosseguir.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Treinamento e Avaliação dos Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    # 'SVM': SVC(probability=True, random_state=42, class_weight='balanced') # SVM pode ser lento\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "if 'X_train_scaled' in globals(): # Verificar se os dados de treino existem\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\n--- Treinando {model_name} ---\")\n",
    "        # Usar dados escalados para modelos sensíveis à escala, e não escalados para baseados em árvores (opcional)\n",
    "        # Aqui, vamos usar escalados para todos por consistência, mas RF/GBM não requerem necessariamente.\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        # roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr') if y_pred_proba is not None and y_test.nunique() > 1 else 'N/A'\n",
    "        # Para AUC com multiclasse, precisa ajustar a estratégia (ovr, ovo) e como y_pred_proba é formatado\n",
    "        # Simplificando para o relatório, focaremos nas outras métricas ou faremos binário para AUC.\n",
    "        \n",
    "        results[model_name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}\n",
    "        best_models[model_name] = model # Salvar o modelo treinado\n",
    "        \n",
    "        print(f\"Resultados para {model_name}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1-score: {f1:.4f}\")\n",
    "        # print(f\"  ROC AUC: {roc_auc if isinstance(roc_auc, str) else roc_auc:.4f}\")\n",
    "        \n",
    "        print(\"\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        \n",
    "        print(\"\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "        \n",
    "    # Exibir resultados consolidados\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(\"\n--- Resultados Consolidados dos Modelos ---\")\n",
    "    display(df_results.sort_values(by='F1-score', ascending=False))\n",
    "else:\n",
    "    print(\"Dados de treinamento não disponíveis. Modelagem não realizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Otimização de Hiperparâmetros (Exemplo para Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Random Forest' in best_models: # Se o Random Forest foi treinado\n",
    "    print(\"\n--- Otimizando Hiperparâmetros para Random Forest (Exemplo) ---\")\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200], # Reduzido para exemplo rápido\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    # Usar TimeSeriesSplit para validação cruzada se os dados tiverem ordem temporal forte\n",
    "    # cv_splitter = TimeSeriesSplit(n_splits=3) \n",
    "    cv_splitter = 3 # Para CV padrão\n",
    "    \n",
    "    grid_search_rf = GridSearchCV(estimator=RandomForestClassifier(random_state=42, class_weight='balanced'), \n",
    "                                param_grid=param_grid_rf, \n",
    "                                cv=cv_splitter, \n",
    "                                scoring='f1_weighted', \n",
    "                                n_jobs=-1, \n",
    "                                verbose=1)\n",
    "    \n",
    "    # grid_search_rf.fit(X_train_scaled, y_train) # Descomentar para rodar (pode ser demorado)\n",
    "    \n",
    "    # print(f\"Melhores Hiperparâmetros para Random Forest: {grid_search_rf.best_params_}\")\n",
    "    # print(f\"Melhor F1-score (weighted) da CV: {grid_search_rf.best_score_:.4f}\")\n",
    "    \n",
    "    # # Avaliar o modelo otimizado no conjunto de teste\n",
    "    # best_rf_model = grid_search_rf.best_estimator_\n",
    "    # y_pred_best_rf = best_rf_model.predict(X_test_scaled)\n",
    "    # print(\"\nResultados do Random Forest Otimizado no Teste:\")\n",
    "    # print(classification_report(y_test, y_pred_best_rf, zero_division=0))\n",
    "    \n",
    "    # # Atualizar o melhor modelo salvo se o otimizado for melhor\n",
    "    # # best_models['Random Forest_Optimized'] = best_rf_model \n",
    "    print(\"GridSearchCV para Random Forest está comentado para execução rápida. Descomente para otimizar.\")\n",
    "else:\n",
    "    print(\"Random Forest não foi treinado, otimização de hiperparâmetros pulada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Seleção e Salvamento do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o melhor modelo com base no F1-score (ou outra métrica de interesse)\n",
    "if results: # Se houver resultados\n",
    "    df_results_sorted = df_results.sort_values(by='F1-score', ascending=False)\n",
    "    best_model_name = df_results_sorted.index[0]\n",
    "    final_model = best_models[best_model_name]\n",
    "    print(f\"\nMelhor modelo selecionado: {best_model_name} com F1-score: {df_results_sorted.iloc[0]['F1-score']:.4f}\")\n",
    "    \n",
    "    # Salvar o modelo treinado para uso na API de inferência\n",
    "    model_filename = f'/home/ubuntu/tcc_kelly_castro/notebooks/best_failure_prediction_model.joblib'\n",
    "    joblib.dump(final_model, model_filename)\n",
    "    print(f'Melhor modelo ({best_model_name}) salvo em {model_filename}')\n",
    "    \n",
    "    # Salvar também as colunas usadas no treinamento para garantir consistência na inferência\n",
    "    model_columns = list(X_train.columns)\n",
    "    columns_filename = '/home/ubuntu/tcc_kelly_castro/notebooks/model_columns.json'\n",
    "    with open(columns_filename, 'w') as f:\n",
    "        json.dump(model_columns, f)\n",
    "    print(f'Colunas do modelo salvas em {columns_filename}')\n",
    "else:\n",
    "    print(\"Nenhum modelo foi treinado ou avaliado. Não é possível salvar o melhor modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusões Preliminares e Próximos Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Este notebook demonstrou o processo de carregamento dos dados de features, EDA, pré-processamento, treinamento e avaliação de modelos de machine learning para predição de falhas em turbinas eólicas.\n",
    "- O modelo [Nome do Melhor Modelo] apresentou o melhor desempenho com base na métrica F1-score.\n",
    "- O modelo treinado e o scaler foram salvos e podem ser usados pela função Lambda da API de inferência.\n",
    "\n",
    "**Próximos Passos:**\n",
    "1.  Desenvolver a função Lambda para a API de inferência, que carregará o modelo salvo e o scaler para realizar predições em novos dados.\n",
    "2.  Configurar o API Gateway para expor essa função Lambda como um endpoint HTTP.\n",
    "3.  Desenvolver o dashboard frontend para consumir essa API e visualizar as predições.\n",
    "4.  Integrar todos os componentes e realizar testes de ponta a ponta.\n",
    "5.  Detalhar os resultados e discussões no documento do TCC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

